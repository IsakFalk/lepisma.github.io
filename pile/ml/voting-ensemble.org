#+TITLE: Voting Ensemble
#+SETUPFILE: ../assets/export.setup

#+BEGIN_QUOTE
This is a test notebook for trying out sagemath features
#+END_QUOTE

For binary classification, if there are $n$ component models and the rate of
success of each model is $q$, then the rate of success of a /majority voting
ensemble/ can be given using the binomial distribution.

#+BEGIN_SRC sage :session :eval never-export :exports none :results none
import numpy as np
var("n, m, q, c")

binom_pmf(p) = binomial(n, m) * p ^ m * (1 - p) ^ (n - m)
#+END_SRC

For a simple case of $n = 21$ and $q = 0.5$, this means that the ensemble
success is given by:

#+BEGIN_SRC sage :session :eval never-export :exports both :results output
sum(binom_pmf(0.5).subs(n == 21), m, 11, 21)
#+END_SRC

#+RESULTS:
: 0.5

Notice that $m$ is summed from 11 to 21 which is the zone of majority. A plot of
varying $q$ values follows:

#+BEGIN_SRC sage :session :eval never-export :exports both :file ./voting-ensemble/two-class.png
plot(sum(binom_pmf(q).subs(n = 21), m, 11, 21), (q, 0.001, 0.999))
#+END_SRC

#+RESULTS:
[[file:./voting-ensemble/two-class.png]]

* Multiclass

Now assume we have $c$ classes. The models have a par accuracy of $1/c$ now.
This asks for a question whether a success rate (call it $q$ as before) greater
than $1 - 1/c$ (or some other value) will result in an ensemble with better
performance than any single one.

For a simple case of 3 classes, we have the par error as $1/3$ and for the
ensemble to be right, we need at least $\lfloor n/3 \rfloor + 1$ models to be /right/.
Meaning the success rate for the ensemble would be:

#+BEGIN_SRC sage :session :eval never-export :exports both :results output
float(sum(binom_pmf(1/3).subs(n == 21), m, 8, 21))
#+END_SRC

#+RESULTS:
: 0.3992381153824027

Okay so it does better than the $1/3$ value.

For 7 classes:

#+BEGIN_SRC sage :session :eval never-export :exports both :results output
float(sum(binom_pmf(1/7).subs(n == 21), m, 4, 21))
#+END_SRC

#+RESULTS:
: 0.3523243319568171

A plot of $q$ vs ensemble success for 7 classes follows:
 
#+BEGIN_SRC sage :session :eval never-export :exports both :file voting-ensemble/seven-class.png
plot(sum(binom_pmf(q).subs(n == 21), m, 4, 21), (q, 0.001, 0.999))
#+END_SRC

#+RESULTS:
[[file:voting-ensemble/seven-class.png]]

* Critical /q/

So you don't need to be a above the $1/c$ threshold in accuracy to gain using a
voting ensemble. This means, even a /poorer/ than random classifier will gain
here. In general, any $q$ that makes the following true will be good:

#+BEGIN_SRC sage :session :eval never-export :exports both :results output
sum(binom_pmf(q), m, floor(n/c + 1), n) > 1/c
#+END_SRC

#+RESULTS:
: sum(q^m*(-q + 1)^(-m + n)*binomial(n, m), m, floor(n/c) + 1, n) > (1/c)

Slight increase in $q$ around this critical value help a lot (as seen from the
curves).
