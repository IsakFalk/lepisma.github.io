#+TITLE: Searching for Strassen multiplication rule
#+SETUPFILE: ../../assets/export.setup

#+BEGIN_QUOTE
This page is a work in progress
#+END_QUOTE

Strassen algorithm is an $\mathcal{O}(N^{2.8074})$ algorithm for multiplying two
square matrices. One major part of the algorithm describes a bunch of
transformations for the submatrices involved. The transformations are mostly
non-intuitive and so the situation looks good playground to try some symbolic
computation and searching.

#+BEGIN_aside
See the [[https://en.wikipedia.org/wiki/Strassen_algorithm#Algorithm][wikipedia page]] for the transformations in the algorithm. The basic idea
is to find a set of multiples with cardinality < 8 (since we already do 8
multiplications in the normal case) which is then manipulated using $\pm$
operators to give the values we want.
#+END_aside

* The general idea

Leaving the specifics behind, the main idea here is to transform a represention
of an object in a /non-commutative/ [fn::This is required for matrices] ring to
another with lesser number of muliplications (since they might be costly) as
compared to a basic canonical form. These multiplcations (and additions) are
applied on certain fixed set of objects. As an example, consider the popular
situation of multiplying two complex numbers $a + ib$ and $c + id$. The naive
representation of the product can be given as:

\[ (ac - bd) + i(ad + bc) \]

This representation uses 4 multiplications ($ac$, $bd$, $ad$ and $bc$) while the
following, equivalent representation, uses 3 ($ac$, $bd$ and $(a + b)(c + d)$):

\[ (ac - bd) + i((a + b)(c + d) - ac - bd) \]

Transformations like these are useful /if/ there are differences in the resources
requirement for various operations (and there are).

Similar problem arises when multiplying two square matrices $A$ and $B$ to
produce $C$. If we break each of the matrices involved like shown below, we get
a problem pretty similar to the complex number multiplication:

\begin{align*}
X = \begin{bmatrix}
   X_{11} & X_{12} \\
   X_{21} & X_{22} \\
\end{bmatrix}
\end{align*}

In the matrix version, we have the following results to achieve:

\begin{align}
\label{eq:simple}
C_{11} &= A_{11}B_{11} + A_{12}B_{21} \\
C_{12} &= A_{11}B_{12} + A_{12}B_{22} \nonumber \\
C_{21} &= A_{21}B_{11} + A_{22}B_{21} \nonumber \\
C_{22} &= A_{21}B_{12} + A_{22}B_{22} \nonumber \\
\end{align}

This needs 8 multiplications. Strassen algorithm does it in 7 (see the
intermediate transformations in wikipedia [[https://en.wikipedia.org/wiki/Strassen_algorithm#Algorithm][page]]). Automating this exact procedure
probably is not very hard and can be done by simple randomized optimization
algorithms (so that we don't have to dig in the underlying mechanics). In fact I
will try to do this first. The bigger problem is to have a general way to
transform expression with certain needs in mind.

* Direct search

For generating the intermediate forms $M_{i}$ (as described in the wikipedia
page) we use one multiplication, the first operand of which is a result of
arbitrary number of sum and negation operations over $\{A_{11}, A_{12}, A_{21},
A_{22}, 0 \}$ with the constraints that the result is not $0$. Similarly for the
second operand with set of submatrices of type $B_{ij}$. This results in
$M_{i}s$ getting pulled from the set $\{A_{11}, A_{12}, A_{21}, A_{22}\} \times
\{B_{11}, B_{12}, B_{21}, B_{22}\}$ (with possible integral coefficients).

One way to proceed from here is to use the products $A_{i}B_{j}$ to represent
the desired result (see \ref{eq:simple}) in a matrix as shown below:

#+BEGIN_aside
This reminds me, we need a /shape checker/ for matrices in Python in the spirit
of mypy. I wonder how useful other users deem it.
#+END_aside

#+BEGIN_SRC sage :session :eval never-export :exports both :results none
import numpy as np
# Shape 4 (C) x 16 (A x B)
output = np.array([[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                   [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
                   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],
                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]])
#+END_SRC

For the transformation from $M_i$ to the output (represented in a way)

TODO. /Mess ahead/.

#+BEGIN_SRC sage :session :eval never-export :exports both :results output
import numpy as np
Y = np.random.randint(-1, 2, (7, 16)) # 7x16
X = output.dot(np.linalg.pinv(Y)) # 4x16
# minimize
np.linalg.norm(X, 2)
#+END_SRC

Constraint the rows of Y to be a defined thing. Each row in Y can be written
as the (flattened) outer product of [a b c d] and [x y w z]. Here the first
vector represents the As and second the Bs. In both these vectors, there
should be at least 1 and at most 2 values active (active meaning non zero; 1
or -1).

For X, we need at least one item active in each row.

Doing that outer things gives

#+BEGIN_SRC sage :session :eval never-export :exports both :results output
Y = array([[ 1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1, 0,  0,  1],
           [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1, 0,  0,  0],
           [ 0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0],
           [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 0,  1,  0],
           [ 0,  0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0, 0,  0,  0],
           [-1, -1,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0, 0,  0,  0],
           [ 0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0, 0, -1, -1]])
#+END_SRC

* Better solutions

Keeping the obviously better solution aside for a moment, we have a lot
possibilities of elegance even in the search. From the top of my head, there are
the following two:

1. Start with a /correct/ output representation and expand the terms so as to
   create a valid solution at each step. This needs to go on til we get the
   desired amount of shared terms.
2. Generate solution with less constraints and verify the correctness with a
   symbolic system like sagemath or proof system like coq.
